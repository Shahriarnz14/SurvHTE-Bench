{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scenario_data(h5_file_path, scenario_num):\n",
    "    key = f\"scenario_{scenario_num}/data\"\n",
    "    with pd.HDFStore(h5_file_path, mode='r') as store:\n",
    "        if key not in store:\n",
    "            return None  # Scenario not found\n",
    "        df = store[key]\n",
    "        metadata = store.get_storer(key).attrs.metadata\n",
    "    return {\"dataset\": df, \"metadata\": metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_files = [\n",
    "    \"../synthetic_data/RCT_0_5.h5\",\n",
    "    \"../synthetic_data/RCT_0_05.h5\",\n",
    "    \"../synthetic_data/e_X.h5\",\n",
    "    \"../synthetic_data/e_X_U.h5\",\n",
    "    \"../synthetic_data/e_X_no_overlap.h5\",\n",
    "    \"../synthetic_data/e_X_info_censor.h5\",\n",
    "    \"../synthetic_data/e_X_U_info_censor.h5\",\n",
    "    \"../synthetic_data/e_X_no_overlap_info_censor.h5\"\n",
    "]\n",
    "\n",
    "experiment_setups = {}\n",
    "\n",
    "for path in store_files:\n",
    "    base_name = os.path.splitext(os.path.basename(path))[0]  # e.g. RCT_0_5\n",
    "    scenario_dict = {}\n",
    "    for scenario in range(1, 11):\n",
    "        try:\n",
    "            result = load_scenario_data(path, scenario)\n",
    "            if result is not None:\n",
    "                scenario_dict[f\"scenario_{scenario}\"] = result\n",
    "        except Exception as e:\n",
    "            # Log or ignore as needed\n",
    "            continue\n",
    "    experiment_setups[base_name] = scenario_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>observed_time</th>\n",
       "      <th>event</th>\n",
       "      <th>W</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135488</td>\n",
       "      <td>0.887852</td>\n",
       "      <td>0.932606</td>\n",
       "      <td>0.445568</td>\n",
       "      <td>0.388236</td>\n",
       "      <td>0.151609</td>\n",
       "      <td>0.205535</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>0.061394</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>1.803019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.732630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.257596</td>\n",
       "      <td>0.657368</td>\n",
       "      <td>0.492617</td>\n",
       "      <td>0.964238</td>\n",
       "      <td>0.800984</td>\n",
       "      <td>0.597208</td>\n",
       "      <td>0.255785</td>\n",
       "      <td>0.228566</td>\n",
       "      <td>0.732630</td>\n",
       "      <td>0.732630</td>\n",
       "      <td>1.689546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.162856</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455205</td>\n",
       "      <td>0.801058</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>0.769458</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.370382</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.176016</td>\n",
       "      <td>0.162856</td>\n",
       "      <td>0.162856</td>\n",
       "      <td>1.256329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.050340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292809</td>\n",
       "      <td>0.610914</td>\n",
       "      <td>0.913027</td>\n",
       "      <td>0.300115</td>\n",
       "      <td>0.248599</td>\n",
       "      <td>0.038464</td>\n",
       "      <td>0.409829</td>\n",
       "      <td>0.381909</td>\n",
       "      <td>0.050340</td>\n",
       "      <td>0.050340</td>\n",
       "      <td>1.241777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.524607</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666392</td>\n",
       "      <td>0.987533</td>\n",
       "      <td>0.468270</td>\n",
       "      <td>0.123287</td>\n",
       "      <td>0.916031</td>\n",
       "      <td>0.342961</td>\n",
       "      <td>0.791330</td>\n",
       "      <td>0.524607</td>\n",
       "      <td>1.121968</td>\n",
       "      <td>0.524607</td>\n",
       "      <td>1.516613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  observed_time  event  W        X1        X2        X3        X4  \\\n",
       "0   0       0.054267      1  0  0.135488  0.887852  0.932606  0.445568   \n",
       "1   1       0.732630      1  1  0.257596  0.657368  0.492617  0.964238   \n",
       "2   2       0.162856      1  1  0.455205  0.801058  0.041718  0.769458   \n",
       "3   3       0.050340      1  1  0.292809  0.610914  0.913027  0.300115   \n",
       "4   4       0.524607      1  0  0.666392  0.987533  0.468270  0.123287   \n",
       "\n",
       "         X5        U1        U2        T0        T1         T         C  \n",
       "0  0.388236  0.151609  0.205535  0.054267  0.061394  0.054267  1.803019  \n",
       "1  0.800984  0.597208  0.255785  0.228566  0.732630  0.732630  1.689546  \n",
       "2  0.003171  0.370382  0.223214  0.176016  0.162856  0.162856  1.256329  \n",
       "3  0.248599  0.038464  0.409829  0.381909  0.050340  0.050340  1.241777  \n",
       "4  0.916031  0.342961  0.791330  0.524607  1.121968  0.524607  1.516613  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_setups['RCT_0_5']['scenario_1']['dataset'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_idx0</th>\n",
       "      <th>random_idx1</th>\n",
       "      <th>random_idx2</th>\n",
       "      <th>random_idx3</th>\n",
       "      <th>random_idx4</th>\n",
       "      <th>random_idx5</th>\n",
       "      <th>random_idx6</th>\n",
       "      <th>random_idx7</th>\n",
       "      <th>random_idx8</th>\n",
       "      <th>random_idx9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47390</td>\n",
       "      <td>5618</td>\n",
       "      <td>14210</td>\n",
       "      <td>46970</td>\n",
       "      <td>4203</td>\n",
       "      <td>16369</td>\n",
       "      <td>24535</td>\n",
       "      <td>45204</td>\n",
       "      <td>45725</td>\n",
       "      <td>45885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38566</td>\n",
       "      <td>46218</td>\n",
       "      <td>39045</td>\n",
       "      <td>7253</td>\n",
       "      <td>22759</td>\n",
       "      <td>34401</td>\n",
       "      <td>28889</td>\n",
       "      <td>38471</td>\n",
       "      <td>45822</td>\n",
       "      <td>37471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32814</td>\n",
       "      <td>20226</td>\n",
       "      <td>40012</td>\n",
       "      <td>4854</td>\n",
       "      <td>27351</td>\n",
       "      <td>39165</td>\n",
       "      <td>25359</td>\n",
       "      <td>14516</td>\n",
       "      <td>25717</td>\n",
       "      <td>29860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41393</td>\n",
       "      <td>39492</td>\n",
       "      <td>27153</td>\n",
       "      <td>19041</td>\n",
       "      <td>33009</td>\n",
       "      <td>19822</td>\n",
       "      <td>21243</td>\n",
       "      <td>41228</td>\n",
       "      <td>955</td>\n",
       "      <td>23901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12564</td>\n",
       "      <td>17823</td>\n",
       "      <td>48976</td>\n",
       "      <td>18458</td>\n",
       "      <td>22756</td>\n",
       "      <td>28169</td>\n",
       "      <td>45851</td>\n",
       "      <td>36620</td>\n",
       "      <td>29824</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>15948</td>\n",
       "      <td>39245</td>\n",
       "      <td>30779</td>\n",
       "      <td>48178</td>\n",
       "      <td>45056</td>\n",
       "      <td>4892</td>\n",
       "      <td>528</td>\n",
       "      <td>7486</td>\n",
       "      <td>31042</td>\n",
       "      <td>38267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>11102</td>\n",
       "      <td>29624</td>\n",
       "      <td>40779</td>\n",
       "      <td>3136</td>\n",
       "      <td>45904</td>\n",
       "      <td>41903</td>\n",
       "      <td>45682</td>\n",
       "      <td>36621</td>\n",
       "      <td>33204</td>\n",
       "      <td>38070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>16338</td>\n",
       "      <td>8986</td>\n",
       "      <td>19293</td>\n",
       "      <td>35651</td>\n",
       "      <td>10172</td>\n",
       "      <td>17947</td>\n",
       "      <td>38843</td>\n",
       "      <td>18310</td>\n",
       "      <td>2765</td>\n",
       "      <td>12581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>32478</td>\n",
       "      <td>32134</td>\n",
       "      <td>11955</td>\n",
       "      <td>36939</td>\n",
       "      <td>33266</td>\n",
       "      <td>41932</td>\n",
       "      <td>43910</td>\n",
       "      <td>21691</td>\n",
       "      <td>40801</td>\n",
       "      <td>33527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>23102</td>\n",
       "      <td>2305</td>\n",
       "      <td>33545</td>\n",
       "      <td>20070</td>\n",
       "      <td>20726</td>\n",
       "      <td>1875</td>\n",
       "      <td>26988</td>\n",
       "      <td>24790</td>\n",
       "      <td>17795</td>\n",
       "      <td>39733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       random_idx0  random_idx1  random_idx2  random_idx3  random_idx4  \\\n",
       "idx                                                                      \n",
       "0            47390         5618        14210        46970         4203   \n",
       "1            38566        46218        39045         7253        22759   \n",
       "2            32814        20226        40012         4854        27351   \n",
       "3            41393        39492        27153        19041        33009   \n",
       "4            12564        17823        48976        18458        22756   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "49995        15948        39245        30779        48178        45056   \n",
       "49996        11102        29624        40779         3136        45904   \n",
       "49997        16338         8986        19293        35651        10172   \n",
       "49998        32478        32134        11955        36939        33266   \n",
       "49999        23102         2305        33545        20070        20726   \n",
       "\n",
       "       random_idx5  random_idx6  random_idx7  random_idx8  random_idx9  \n",
       "idx                                                                     \n",
       "0            16369        24535        45204        45725        45885  \n",
       "1            34401        28889        38471        45822        37471  \n",
       "2            39165        25359        14516        25717        29860  \n",
       "3            19822        21243        41228          955        23901  \n",
       "4            28169        45851        36620        29824        12711  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "49995         4892          528         7486        31042        38267  \n",
       "49996        41903        45682        36621        33204        38070  \n",
       "49997        17947        38843        18310         2765        12581  \n",
       "49998        41932        43910        21691        40801        33527  \n",
       "49999         1875        26988        24790        17795        39733  \n",
       "\n",
       "[50000 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_repeat_setups = pd.read_csv(\"../synthetic_data/idx_split.csv\").set_index(\"idx\")\n",
    "experiment_repeat_setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_REPEATS_TO_INCLUDE = 10  # max 10\n",
    "# NUM_TRAINING_DATA_POINTS = 5000 # max 45000\n",
    "TEST_SIZE = 5000\n",
    "# IMPUTATION_METHOD = \"Pseudo_obs\" # \"Margin\", \"IPCW-T\", \"Pseudo_obs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_methods_list = ['Pseudo_obs', 'Margin', 'IPCW-T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_training_data_points_list = [50, 100, 200, 300, 400, 500, 700, 1000, 2000, 3000, 4000, 5000, 10000, 20000, 30000]\n",
    "num_training_data_points_list = [200, 300, 500, 1000, 2000, 5000, 10000, 20000]\n",
    "len(num_training_data_points_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pickle_path = f\"../synthetic_data/imputed_times_lookup.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading imputation times from existing file.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if os.path.exists(output_pickle_path):\n",
    "    print(\"Loading imputation times from existing file.\")\n",
    "    with open(output_pickle_path, 'rb') as f:\n",
    "        imputed_times = pickle.load(f)\n",
    "else:\n",
    "    print(\"Imputation times not found, creating new file.\")\n",
    "    imputed_times = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Imputation Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of \"notebooks\" to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from models_causal_impute.survival_eval_impute import SurvivalEvalImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_split(dataset_df, experiment_repeat_setups, random_idx_col_list, num_training_data_points=5000, test_size=5000):\n",
    "    split_results = {}\n",
    "\n",
    "    for rand_idx in random_idx_col_list:\n",
    "        random_idx = experiment_repeat_setups[rand_idx].values\n",
    "        test_ids = random_idx[-test_size:]\n",
    "        train_ids = random_idx[:min(num_training_data_points, len(random_idx) - test_size)]\n",
    "\n",
    "        X_cols = [c for c in dataset_df.columns if c.startswith(\"X\") and c[1:].isdigit()]\n",
    "        \n",
    "        train_df = dataset_df[dataset_df['id'].isin(train_ids)]\n",
    "        test_df = dataset_df[dataset_df['id'].isin(test_ids)]\n",
    "\n",
    "        X_train = train_df[X_cols].to_numpy()\n",
    "        W_train = train_df[\"W\"].to_numpy()\n",
    "        Y_train = train_df[[\"observed_time\", \"event\"]].to_numpy()\n",
    "\n",
    "        X_test = test_df[X_cols].to_numpy()\n",
    "        W_test = test_df[\"W\"].to_numpy()\n",
    "        Y_test = test_df[[\"observed_time\", \"event\"]].to_numpy()\n",
    "\n",
    "        cate_test_true = (test_df[\"T1\"] - test_df[\"T0\"]).to_numpy()\n",
    "\n",
    "        split_results[rand_idx] = (X_train, W_train, Y_train, X_test, W_test, Y_test, cate_test_true)\n",
    "\n",
    "    return split_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_idx_col_list = experiment_repeat_setups.columns.to_list()\n",
    "# start_time = end_time = 0\n",
    "\n",
    "# for imputation_method_idx in trange(len(imputation_methods_list), desc=\"Imputation Methods\"):\n",
    "#     imputation_method = imputation_methods_list[imputation_method_idx]\n",
    "\n",
    "#     if imputed_times.get(imputation_method) is None:\n",
    "#         print(f\"Imputation times not found for {imputation_method}, creating new entry.\")\n",
    "#         imputed_times[imputation_method] = {}\n",
    "\n",
    "#     # for setup_name, setup_dict in tqdm(experiment_setups.items(), desc=\"Experiment Setups\"):\n",
    "#     for setup_name, setup_dict in experiment_setups.items():\n",
    "\n",
    "#         # Check if imputed_times[imputation_method] has the setup_name\n",
    "#         if setup_name not in imputed_times[imputation_method]:\n",
    "#             print(f\"Creating new entry for '{setup_name}' in imputed times['{imputation_method}'].\")\n",
    "#             imputed_times[imputation_method][setup_name] = {}\n",
    "\n",
    "#         for scenario_key in setup_dict:\n",
    "#             dataset_df = setup_dict[scenario_key][\"dataset\"]\n",
    "\n",
    "#             # check if imputed_times[imputation_method][setup_name] has the scenario_key\n",
    "#             if scenario_key not in imputed_times[imputation_method][setup_name]:\n",
    "#                 print(f\"Creating new entry for '{scenario_key}' in imputed times['{imputation_method}']['{setup_name}'].\")\n",
    "#                 imputed_times[imputation_method][setup_name][scenario_key] = {}\n",
    "\n",
    "#             for num_training_data_points in num_training_data_points_list:\n",
    "\n",
    "#                 split_dict = prepare_data_split(dataset_df, experiment_repeat_setups, random_idx_col_list, num_training_data_points)\n",
    "\n",
    "#                 # check if imputed_times[imputation_method][setup_name][scenario_key] has the num_training_data_points\n",
    "#                 if num_training_data_points not in imputed_times[imputation_method][setup_name][scenario_key]:\n",
    "#                     # print(f\"Creating new entry for '{num_training_data_points}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}'].\")\n",
    "#                     imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] = {}\n",
    "\n",
    "#                 for rand_idx in random_idx_col_list:\n",
    "#                     X_train, W_train, Y_train, X_test, W_test, Y_test, cate_test_true = split_dict[rand_idx]\n",
    "\n",
    "#                     # Check if imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] has the rand_idx\n",
    "#                     if rand_idx not in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points]:\n",
    "#                         # print(f\"Creating new entry for '{rand_idx}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}']['{num_training_data_points}'].\")\n",
    "#                         imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx] = {}\n",
    "#                     elif rand_idx in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] and \\\n",
    "#                         \"runtime\" in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx]:\n",
    "#                         # print(f\"Skipping existing entry for '{rand_idx}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}'][{num_training_data_points}].\")\n",
    "#                         continue\n",
    "\n",
    "#                     start_time = time.time()\n",
    "\n",
    "#                     # impute the missing values\n",
    "#                     survival_imputer = SurvivalEvalImputer(imputation_method=imputation_method, verbose=False)\n",
    "#                     Y_train_imputed, Y_test_imputed = survival_imputer.fit_transform(Y_train, Y_test)\n",
    "\n",
    "#                     end_time = time.time()\n",
    "\n",
    "#                     imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx] = {\n",
    "#                         \"Y_train_imputed\": Y_train_imputed,\n",
    "#                         \"Y_test_imputed\": Y_test_imputed,\n",
    "#                         \"runtime\": end_time - start_time\n",
    "#                     }\n",
    "#                 print(f\"'{imputation_method}' Imputation completed for '{setup_name}', '{scenario_key}', \" +\n",
    "#                       f\"num_training: {num_training_data_points}, {rand_idx} in {end_time - start_time:.0f} seconds.\")\n",
    "                \n",
    "#             # Save progress to disk\n",
    "#             with open(output_pickle_path, \"wb\") as f:\n",
    "#                 pickle.dump(imputed_times, f)\n",
    "            \n",
    "#             # break\n",
    "#         # break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# # impute the missing values\n",
    "# survival_imputer = SurvivalEvalImputer(imputation_method=imputation_method, verbose=False)\n",
    "# Y_train_imputed, Y_test_imputed = survival_imputer.fit_transform(Y_train, Y_test)\n",
    "\n",
    "# end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Pseudo_obs Imputation Times For e_X_U and e_X_U_info_censor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scenario_1', 'scenario_2', 'scenario_5', 'scenario_8', 'scenario_9'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_times['Pseudo_obs']['e_X_U'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imputation Methods: 100%|██████████| 3/3 [00:00<00:00, 9313.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcting imputation method: Pseudo_obs\n",
      "(No Correction Needed) Skipping imputation for setup:  RCT_0_5\n",
      "(No Correction Needed) Skipping imputation for setup:  RCT_0_05\n",
      "(No Correction Needed) Skipping imputation for setup:  e_X\n",
      "Correcting imputation for updated version of setup:  e_X_U\n",
      "(No Correction Needed) Skipping imputation for setup:  e_X_no_overlap\n",
      "(No Correction Needed) Skipping imputation for setup:  e_X_info_censor\n",
      "Correcting imputation for updated version of setup:  e_X_U_info_censor\n",
      "(No Correction Needed) Skipping imputation for setup:  e_X_no_overlap_info_censor\n",
      "[No Correction Needed] Skipping imputation method: Margin.\n",
      "[No Correction Needed] Skipping imputation method: IPCW-T.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random_idx_col_list = experiment_repeat_setups.columns.to_list()\n",
    "start_time = end_time = 0\n",
    "\n",
    "for imputation_method_idx in trange(len(imputation_methods_list), desc=\"Imputation Methods\"):\n",
    "    imputation_method = imputation_methods_list[imputation_method_idx]\n",
    "\n",
    "\n",
    "    ####################################################################\n",
    "    if imputation_method != \"Pseudo_obs\":\n",
    "        print(f\"[No Correction Needed] Skipping imputation method: {imputation_method}.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Correcting imputation method: {imputation_method}\")\n",
    "    ####################################################################\n",
    "\n",
    "\n",
    "    if imputed_times.get(imputation_method) is None:\n",
    "        print(f\"Imputation times not found for {imputation_method}, creating new entry.\")\n",
    "        imputed_times[imputation_method] = {}\n",
    "\n",
    "    # for setup_name, setup_dict in tqdm(experiment_setups.items(), desc=\"Experiment Setups\"):\n",
    "    for setup_name, setup_dict in experiment_setups.items():\n",
    "\n",
    "\n",
    "        ####################################################################\n",
    "        if setup_name in ['e_X_U', 'e_X_U_info_censor']:\n",
    "            print(\"Correcting imputation for updated version of setup: \", setup_name)\n",
    "            imputed_times[imputation_method][setup_name] = {}\n",
    "            # continue\n",
    "        else:\n",
    "            print(\"(No Correction Needed) Skipping imputation for setup: \", setup_name)\n",
    "            continue\n",
    "        ####################################################################\n",
    "\n",
    "\n",
    "        # Check if imputed_times[imputation_method] has the setup_name\n",
    "        if setup_name not in imputed_times[imputation_method]:\n",
    "            print(f\"Creating new entry for '{setup_name}' in imputed times['{imputation_method}'].\")\n",
    "            imputed_times[imputation_method][setup_name] = {}\n",
    "\n",
    "        for scenario_key in setup_dict:\n",
    "            dataset_df = setup_dict[scenario_key][\"dataset\"]\n",
    "\n",
    "            # check if imputed_times[imputation_method][setup_name] has the scenario_key\n",
    "            if scenario_key not in imputed_times[imputation_method][setup_name]:\n",
    "                print(f\"Creating new entry for '{scenario_key}' in imputed times['{imputation_method}']['{setup_name}'].\")\n",
    "                imputed_times[imputation_method][setup_name][scenario_key] = {}\n",
    "\n",
    "            for num_training_data_points in num_training_data_points_list:\n",
    "\n",
    "                split_dict = prepare_data_split(dataset_df, experiment_repeat_setups, random_idx_col_list, num_training_data_points)\n",
    "\n",
    "                # check if imputed_times[imputation_method][setup_name][scenario_key] has the num_training_data_points\n",
    "                if num_training_data_points not in imputed_times[imputation_method][setup_name][scenario_key]:\n",
    "                    # print(f\"Creating new entry for '{num_training_data_points}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}'].\")\n",
    "                    imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] = {}\n",
    "\n",
    "                for rand_idx in random_idx_col_list:\n",
    "                    X_train, W_train, Y_train, X_test, W_test, Y_test, cate_test_true = split_dict[rand_idx]\n",
    "\n",
    "                    # Check if imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] has the rand_idx\n",
    "                    if rand_idx not in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points]:\n",
    "                        # print(f\"Creating new entry for '{rand_idx}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}']['{num_training_data_points}'].\")\n",
    "                        imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx] = {}\n",
    "                    elif rand_idx in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] and \\\n",
    "                        \"runtime\" in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx]:\n",
    "                        # print(f\"Skipping existing entry for '{rand_idx}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}'][{num_training_data_points}].\")\n",
    "                        continue\n",
    "\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    # impute the missing values\n",
    "                    survival_imputer = SurvivalEvalImputer(imputation_method=imputation_method, verbose=False)\n",
    "                    Y_train_imputed, Y_test_imputed = survival_imputer.fit_transform(Y_train, Y_test)\n",
    "\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx] = {\n",
    "                        \"Y_train_imputed\": Y_train_imputed,\n",
    "                        \"Y_test_imputed\": Y_test_imputed,\n",
    "                        \"runtime\": end_time - start_time\n",
    "                    }\n",
    "                print(f\"'{imputation_method}' Imputation completed for '{setup_name}', '{scenario_key}', \" +\n",
    "                      f\"num_training: {num_training_data_points}, {rand_idx} in {end_time - start_time:.0f} seconds.\")\n",
    "                \n",
    "            # Save progress to disk\n",
    "            with open(output_pickle_path, \"wb\") as f:\n",
    "                pickle.dump(imputed_times, f)\n",
    "            \n",
    "            # break\n",
    "        # break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update IPCW-T Imputation Times For All Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['RCT_0_5', 'RCT_0_05', 'e_X', 'e_X_U', 'e_X_no_overlap', 'e_X_info_censor', 'e_X_U_info_censor', 'e_X_no_overlap_info_censor'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_times['IPCW-T'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imputation Methods: 100%|██████████| 3/3 [00:00<00:00, 26829.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[No Correction Needed] Skipping imputation method: Pseudo_obs.\n",
      "[No Correction Needed] Skipping imputation method: Margin.\n",
      "Correcting imputation method: IPCW-T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random_idx_col_list = experiment_repeat_setups.columns.to_list()\n",
    "start_time = end_time = 0\n",
    "\n",
    "for imputation_method_idx in trange(len(imputation_methods_list), desc=\"Imputation Methods\"):\n",
    "    imputation_method = imputation_methods_list[imputation_method_idx]\n",
    "\n",
    "    ####################################################################\n",
    "    if imputation_method != \"IPCW-T\":\n",
    "        print(f\"[No Correction Needed] Skipping imputation method: {imputation_method}.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Correcting imputation method: {imputation_method}\")\n",
    "        imputed_times[imputation_method] = {}\n",
    "    ####################################################################\n",
    "\n",
    "    if imputed_times.get(imputation_method) is None:\n",
    "        print(f\"Imputation times not found for {imputation_method}, creating new entry.\")\n",
    "        imputed_times[imputation_method] = {}\n",
    "\n",
    "    # for setup_name, setup_dict in tqdm(experiment_setups.items(), desc=\"Experiment Setups\"):\n",
    "    for setup_name, setup_dict in experiment_setups.items():\n",
    "\n",
    "        # Check if imputed_times[imputation_method] has the setup_name\n",
    "        if setup_name not in imputed_times[imputation_method]:\n",
    "            print(f\"Creating new entry for '{setup_name}' in imputed times['{imputation_method}'].\")\n",
    "            imputed_times[imputation_method][setup_name] = {}\n",
    "\n",
    "        for scenario_key in setup_dict:\n",
    "            dataset_df = setup_dict[scenario_key][\"dataset\"]\n",
    "\n",
    "            # check if imputed_times[imputation_method][setup_name] has the scenario_key\n",
    "            if scenario_key not in imputed_times[imputation_method][setup_name]:\n",
    "                print(f\"Creating new entry for '{scenario_key}' in imputed times['{imputation_method}']['{setup_name}'].\")\n",
    "                imputed_times[imputation_method][setup_name][scenario_key] = {}\n",
    "\n",
    "            for num_training_data_points in num_training_data_points_list:\n",
    "\n",
    "                split_dict = prepare_data_split(dataset_df, experiment_repeat_setups, random_idx_col_list, num_training_data_points)\n",
    "\n",
    "                # check if imputed_times[imputation_method][setup_name][scenario_key] has the num_training_data_points\n",
    "                if num_training_data_points not in imputed_times[imputation_method][setup_name][scenario_key]:\n",
    "                    # print(f\"Creating new entry for '{num_training_data_points}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}'].\")\n",
    "                    imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] = {}\n",
    "\n",
    "                for rand_idx in random_idx_col_list:\n",
    "                    X_train, W_train, Y_train, X_test, W_test, Y_test, cate_test_true = split_dict[rand_idx]\n",
    "\n",
    "                    # Check if imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] has the rand_idx\n",
    "                    if rand_idx not in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points]:\n",
    "                        # print(f\"Creating new entry for '{rand_idx}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}']['{num_training_data_points}'].\")\n",
    "                        imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx] = {}\n",
    "                    elif rand_idx in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points] and \\\n",
    "                        \"runtime\" in imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx]:\n",
    "                        # print(f\"Skipping existing entry for '{rand_idx}' in imputed times['{imputation_method}']['{setup_name}']['{scenario_key}'][{num_training_data_points}].\")\n",
    "                        continue\n",
    "\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    # impute the missing values\n",
    "                    survival_imputer = SurvivalEvalImputer(imputation_method=imputation_method, verbose=False)\n",
    "                    Y_train_imputed, Y_test_imputed = survival_imputer.fit_transform(Y_train, Y_test)\n",
    "\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    imputed_times[imputation_method][setup_name][scenario_key][num_training_data_points][rand_idx] = {\n",
    "                        \"Y_train_imputed\": Y_train_imputed,\n",
    "                        \"Y_test_imputed\": Y_test_imputed,\n",
    "                        \"runtime\": end_time - start_time\n",
    "                    }\n",
    "                print(f\"'{imputation_method}' Imputation completed for '{setup_name}', '{scenario_key}', \" +\n",
    "                      f\"num_training: {num_training_data_points}, {rand_idx} in {end_time - start_time:.0f} seconds.\")\n",
    "                \n",
    "            # Save progress to disk\n",
    "            with open(output_pickle_path, \"wb\") as f:\n",
    "                pickle.dump(imputed_times, f)\n",
    "            \n",
    "            # break\n",
    "        # break\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_survival_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
